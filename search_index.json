[
["index.html", "DfT R Cookbook Chapter 1 Why do we need another book? 1.1 Coding standards 1.2 Data 1.3 Work in progress", " DfT R Cookbook Isi Avbulimen, Hannah Bougdah, Tamsin Forbes, Tim Taylor 2019-09-05 Chapter 1 Why do we need another book? R is a very flexible programming language, which inevitably means there are lots of ways to achieve the same result. This is true of all programming languages, but is particularly exaggerated in R which makes use of ‘meta-programming’. For example, here is how to calculate a new variable using standard R and filter on a variable: # Calculate kilometers per litre from miles per gallon mtcars$kpl &lt;- mtcars$mpg * 0.425144 # Select cars with a horsepower greater than 250 &amp; show only mpg and kpl columns mtcars[mtcars$hp &gt; 250, c(&quot;car&quot;, &quot;mpg&quot;, &quot;kpl&quot;)] car mpg kpl 29 15.8 6.717275 31 15.0 6.377160 Here’s the same thing using {tidyverse} style R: mtcars %&gt;% # Calculate kilometers per litre dplyr::mutate( kpl = mpg * 0.425144 ) %&gt;% # Filter cars with a horsepower greater than 250 dplyr::filter( hp &gt; 250 ) %&gt;% # Take only the car, mpg, and newly created kpl columns dplyr::select(car, mpg, kpl) car mpg kpl 29 15.8 6.717275 31 15.0 6.377160 These coding styles are quite different. As people write more code across the Department, it will become increasingly important that code can be handed over to other R users. It is much easier to pick up code written by others if it uses the same coding style you are familiar with. This is the main motivation for this book, to establish a way of coding that represents a sensible default for those who are new to R that is readily transferable across DfT. 1.1 Coding standards Related to this, the Data Science team maintain a coding standards document, that outlines some best practices when writing R code. This is not prescriptive and goes beyond the scope of this document, but might be useful for managing your R projects. 1.2 Data The data used in this book is all opensource or has been created for the purposes of demonstarting various techniques. As well as being availble fro the data folder on the github site [here][(https://github.com/departmentfortransport/R-cookbook/tree/master/data) you can also find the larger data sets at the links below. Road Safety Data Search and Rescue Helicopter data; SARH0112 record level data download available under All data at the bottom of this webpage. Pokemon data, not sure of original source, but borrowed from Matt Dray here 1.3 Work in progress This book is not static - new chapters can be added and current chapters can be amended. Please let us know if you have suggestions by raising an issue here. "],
["basics.html", "Chapter 2 The basics 2.1 R family 2.2 DfT R/RStudio - subject to change 2.3 RStudio IDE 2.4 Projects 2.5 R memory 2.6 A note on rounding 2.7 Assignment operators &lt;- vs = 2.8 Arithmetic operators 2.9 Relational operators 2.10 Logical operators 2.11 Vectors", " Chapter 2 The basics 2.1 R family A few of the common R relations are R is the programming language, born in 1997, based on S, honest. RStudio is a useful integrated development environment (IDE) that makes it cleaner to write, run and organise R code. Rproj is the file extension for an R project, essentially a working directory marker, shortens file paths, keeps everything relevant to your project together and easy to reference. packages are collections of functions written to make specific tasks easier, eg the {stringr} package contains functions to work with strings. Packages are often referred to as libraries in other programming languages. .R is the file extension for a basic R script in which anything not commented out with # is code that is run. .Rmd is the file extension for Rmarkdown an R package useful for producing reports. A .Rmd script is different to a .R script in that the default is text rather than code. Code is placed in code chunks - similar to how a Jupyter Notebook looks. 2.2 DfT R/RStudio - subject to change Which version of R/RStudio should I use at DfT? A good question. Currently the ‘best’ version of R we have available on network is linked to RStudio version 11453. This can be accessed via the Citrix app on the Windows 10 devices, or via Citrix desktop. The local version of RStudio on the Windows 10 devices is currently unusable (user testing is ongoing to change this). There is also a 11423 version of RStudio available which uses slightly older versions of packages. 2.3 RStudio IDE The RStudio integrated development environment has some very useful features which make writing and organising code a lot easier. It’s divided into 3 panes; 2.3.1 Left (bottom left if you have scripts open) this is the Console it shows you what code has been run and outputs. 2.3.2 Top right; Environment, and other tabs Environment tab shows what objects have been created in the global environment in the current session. Connections tab will show any connections you have set up this session, for example, to an SQL server. 2.3.3 Bottom right Files tab shows what directory you are in and the files there. Plots tab shows all the plot outputs created this session, you can navigate through them. Packages tab shows a list of installed packages, if the box in front of the package name is checked then this package has been loaded this session. Help tab can be used to search for help on a topic/package function, it also holds any output from ?function_name help command that has been run in the console, again you can navigate through help topics using the left and right arrows. Viewer tab can be used to view local web content. For some pictures have a look at DfE’s R Training Course getting started with rstudio Or Matt Dray’s Beginner R Featuring Pokemon: the RStudio interface 2.3.4 Other handy buttons in RStudio IDE top left new script icon; blank page with green circle and white cross. top right project icon; 3D transparent light blue cube with R. Use this to create and open projects. 2.3.5 RStudio menu bar a few pointers View contains Zoom In Zoom Out Tools -&gt; Global Options contains many useful setting tabs such as Appearance where you can change the RStudio theme, and Code -&gt; Display where you can set a margin vertical guideline (default is 80 characters). 2.4 Projects Why you should work in an R project, how to set up and project happiness. See this section of Beginner R Featuring Pokemon by Matt Dray. 2.4.1 Folders When you set up a project it is good practise to include separate folders for different types of files such as data; for the data your R code is using output; for files creates by your code R; all your code files, eg .R, .Rmd images 2.4.2 sessionInfo() Include a saved file of the sessionInfo() output, this command prints out the versions of all the packages currently loaded. This information is essential when passing on code as packages can be updated and code breaking changes made. 2.5 R memory R works in RAM, so its memory is only as good as the amount of RAM you have - however this should be sufficient for most tasks. More info in the Memory chapter of Advanced R by Hadley Wickham here. 2.6 A note on rounding For rounding numerical values we have the base function round(x, digits = 0). This rounds the value of the first argument to the specified number of decimal places (default 0). round(c(-1.5, -0.5, 0.5, 1.5, 2.5, 3.5, 4.5)) ## [1] -2 0 0 2 2 4 4 For example, note that 1.5 and 2.5 both round to 2, which is probably not what you were expecting, this is generally referred to as ‘round half to even’. The round() documentation explains all (?round) Note that for rounding off a 5, the IEC 60559 standard (see also ‘IEEE 754’) is expected to be used, ‘go to the even digit’. Therefore round(0.5) is 0 and round(-1.5) is -2. However, this is dependent on OS services and on representation error (since e.g. 0.15 is not represented exactly, the rounding rule applies to the represented number and not to the printed number, and so round(0.15, 1) could be either 0.1 or 0.2). To implement what we consider normal rounding we can use the {janitor} package and the function round_half_up library(janitor) ## ## Attaching package: &#39;janitor&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## chisq.test, fisher.test janitor::round_half_up(c(-1.5, -0.5, 0.5, 1.5, 2.5, 3.5, 4.5)) ## [1] -2 -1 1 2 3 4 5 If we do not have access to the package (or do not want to depend on the package) then we can implement^[see stackoverflow round_half_up_v2 &lt;- function(x, digits = 0) { posneg &lt;- sign(x) z &lt;- abs(x) * 10 ^ digits z &lt;- z + 0.5 z &lt;- trunc(z) z &lt;- z / 10 ^ digits z * posneg } round_half_up_v2(c(-1.5, -0.5, 0.5, 1.5, 2.5, 3.5, 4.5)) ## [1] -2 -1 1 2 3 4 5 2.7 Assignment operators &lt;- vs = To assign or to equal? These are not always the same thing. In R to assign a value to a variable it is advised to use &lt;- rather than =. The latter is generally used for setting parameters inside functions, e.g., my_string &lt;- stringr::str_match(string = &quot;abc&quot;, pattern = &quot;a&quot;). More on assignment operators here. 2.8 Arithmetic operators addition 1 + 2 ## [1] 3 subtraction 5 - 4 ## [1] 1 multiplication 2 * 2 ## [1] 4 division 3 / 2 ## [1] 1.5 exponent 3 ^ 2 ## [1] 9 modulus (remainder on divsion) 14 %% 6 ## [1] 2 integer division 50 %/% 8 ## [1] 6 2.9 Relational operators less than 3.14 &lt; 3.142 ## [1] TRUE greater than 3.14159 &gt; 3 ## [1] TRUE less than or equal to 3 &lt;= 3.14 ## [1] TRUE 3.14 &lt;= 3.14 ## [1] TRUE greater than or equal to 3 &gt;= 3.14 ## [1] FALSE 3.14 &gt;= 3.14 ## [1] TRUE equal to 3 == 3.14159 ## [1] FALSE not equal to 3 != 3.14159 ## [1] TRUE 2.10 Logical operators Logical operations are possible only for numeric, logical or complex types. Note that 0 (or complex version 0 + 0i) is equivalent to FALSE, and all other numbers (numeric or complex) are equivalent to TRUE. not ! x &lt;- c(TRUE, 0, FALSE, -4) !x ## [1] FALSE TRUE TRUE FALSE element-wise and &amp; y &lt;- c(3.14, FALSE, TRUE, 0) x &amp; y ## [1] TRUE FALSE FALSE FALSE first element and &amp;&amp; x &amp;&amp; y ## [1] TRUE element-wise or | x | y ## [1] TRUE FALSE TRUE TRUE first element or || z &lt;- c(0, FALSE, 8) y || z ## [1] TRUE 2.11 Vectors 2.11.1 Types There are four main atomic vector types that you are likely to come across when using R1; logical (TRUE or FALSE), double (3.142), integer (2L) and character (&quot;Awesome&quot;) v1 &lt;- TRUE typeof(v1) ## [1] &quot;logical&quot; v1 &lt;- FALSE typeof(v1) ## [1] &quot;logical&quot; v2 &lt;- 1.5 typeof(v2) ## [1] &quot;double&quot; v2 &lt;- 1 typeof(v2) ## [1] &quot;double&quot; # integer values must be followed by an L to be stored as integers v3 &lt;- 2 typeof(v3) ## [1] &quot;double&quot; v3 &lt;- 2L typeof(v3) ## [1] &quot;integer&quot; v4 &lt;- &quot;Awesome&quot; typeof(v4) ## [1] &quot;character&quot; As well as the atomic vector types you will often encounter two other vector types; Date and factor . As well as some notes here this book also contains fuller sections on both Chapter 5 Working with dates and times Chapter 6 Working with factors Factor vectors are used to represent categorical data. They are actually integer vectors with two additional attributes, levels and class. At this stage it is not worth worrying too much about what attributes are, but is suffiecient to understand that, for factors, the levels attribute gives the possible categories, and combined with the integer values works much like a lookup table. The class attribute is just “factor”. ratings &lt;- factor(c(&quot;good&quot;, &quot;bad&quot;, &quot;bad&quot;, &quot;amazing&quot;)) typeof(ratings) ## [1] &quot;integer&quot; attributes(ratings) ## $levels ## [1] &quot;amazing&quot; &quot;bad&quot; &quot;good&quot; ## ## $class ## [1] &quot;factor&quot; Date vectors are just vectors of class double with an additional class attribute set as “Date”. DfT_birthday &lt;- lubridate::as_date(&quot;1919-08-14&quot;) typeof(DfT_birthday) ## [1] &quot;double&quot; attributes(DfT_birthday) ## $class ## [1] &quot;Date&quot; If we remove the class using unclass() we can reveal the value of the double, which is the number of days since “1970-01-01”2, since DfT’s birthday is before this date, the double is negative. unclass(DfT_birthday) ## [1] -18403 2.11.2 Conversion between atomic vector types Converting between the atomic vector types is done using the as.character, as.integer, as.logical and as.double functions. value &lt;- 1.5 as.integer(value) ## [1] 1 as.character(value) ## [1] &quot;1.5&quot; as.logical(value) ## [1] TRUE Where it is not possible to convert a value you will get a warning message value &lt;- &quot;z&quot; as.integer(value) ## Warning: NAs introduced by coercion ## [1] NA When combining different vector types, coercion will obey the following hierarchy: character, double, integer, logical. typeof(c(9.9, 3L, &quot;pop&quot;, TRUE)) ## [1] &quot;character&quot; typeof(c(9.9, 3L, TRUE)) ## [1] &quot;double&quot; typeof(c(3L, TRUE)) ## [1] &quot;integer&quot; typeof(TRUE) ## [1] &quot;logical&quot; technically there are more, see https://adv-r.hadley.nz/vectors-chap.html#atomic-vectors↩ a special date known as the Unix Epoch↩ "],
["data-import.html", "Chapter 3 Data Importing/Exporting and interaction with other programmes 3.1 Libraries 3.2 Star functions 3.3 Navigating folders 3.4 .rds 3.5 .csv 3.6 .xlsx and .xls 3.7 Exporting to .xlsx 3.8 .sav 3.9 SQL 3.10 GCP", " Chapter 3 Data Importing/Exporting and interaction with other programmes This chapter is for code examples of data importing/exporting and interactions with other programmes and databases. 3.1 Libraries library(tidyverse) library(fs) #cross-platform file systems operations (based on libuv C library) library(knitr) #general purpose tool for dynamic report generation in R library(kableExtra) #presentation of complex tables with customizable styles library(DT) #presentation of tables (wrapper of JavaScript library DataTables) library(DBI) #database connection library(dbplyr) #database connection library(haven) #for importing/exporting SPSS, Stata, and SAS files library(bigrquery) #connecting to GCP BigQuery library(openxlsx) #formatting xlsx outputs library(xltabr) #MoJ RAP enabler built on openxlsx 3.2 Star functions readxl::read_excel readxl::excel_sheets purrr::map_dfr purrr::map_dfc purrr::map2_dfc fs::dir_ls 3.3 Navigating folders A couple of pointers to navigate from your working directory, which, if you’re using R projects (it is highly recommended that you do) will be wherever the .Rproj file is located ### Down To navigate down folders use /. The path given below saves the file my_df.csv in the data folder, which itself is inside the monthly_work folder readr::write_csv( x = my_dataframe , path = &quot;monthly_work/data/my_df.csv&quot; ) 3.3.1 Up To go up a folder use ../. In particular you may need to do this when running Rmarkdown files. Rmarkdown files use their location as the working directory. If you have created an R folder, say, to stash all your scripts in, and a data folder to stash your data files in, then you will need to go up, before going down… The path below goes up one folder, then into the data folder, where the lookup_table.csv is located. lookup_table &lt;- readr::read_csv( file = &quot;../data/lookup_table.csv&quot; ) 3.4 .rds .rds is R’s native file format, any object you create in R can be saved as a .rds file. The functions readRDS and saveRDS are base R functions. #not run saveRDS( object = my_model #specify the R object you want to save , file = &quot;2019_0418_my_model.rds&quot; #give it a name, don&#39;t forget the file extension ) 3.5 .csv We use the functions read_csv and write_csv from the {readr} package (which is part of the {tidyverse}). These are a little bit cleverer than their base counterparts, however, this cleverness can catch you out. The file messy_pokemon_data.csv contains pokemon go captures data which has been deliberately messed up a bit. read_csv imputes the column specification from the first 1000 rows, which is fine if your first 1000 rows are representative of the data type. If not then subsequent data that can’t be coerced into the imputed data type will be replaced with NA. Looking at the column specification below notice that read_csv has recognised time_first_capture as a time type, but not date_first_capture as date type. Given the information that combat_power should be numeric we can see that something is also amiss here as read_csv has guessed character type for this column. pokemon &lt;- readr::read_csv( file = &quot;data/messy_pokemon_data.csv&quot; ) ## Parsed with column specification: ## cols( ## species = col_character(), ## combat_power = col_character(), ## hit_points = col_double(), ## weight_kg = col_double(), ## weight_bin = col_character(), ## height_m = col_double(), ## height_bin = col_character(), ## fast_attack = col_character(), ## charge_attack = col_character(), ## date_first_capture = col_character(), ## time_first_capture = col_time(format = &quot;&quot;) ## ) Let’s have a quick look at some data from these columns pokemon %&gt;% dplyr::select(species, combat_power, date_first_capture, time_first_capture) %&gt;% dplyr::arrange(desc(combat_power)) %&gt;% head() species combat_power date_first_capture time_first_capture electabuzz P962 29/04/2001 08:20:10 pidgey P95 27/11/1969 21:59:32 drowzee P613 18/07/1968 10:36:38 bulbasaur P577 17 June 1997 09:17:17 drowzee P542 04/07/1928 21:54:04 drowzee P518 06/09/1950 17:01:18 The pokemon dataset has less than 1000 rows so read_csv has ‘seen’ the letters mixed in with some of the numbers in the combat_power column. It has guessed at character type because everything it has read in the column can be coerced to character type. What if there are more than 1000 rows? For example, say you have a numeric column, but there are some letters prefixed to the numbers in some of the post-row-1000 rows. These values are still meaningful to you, and with some data wrangling you can extract the actual numbers. Unfortunately read_csv has guessed at type double based on the first 1000 rows and since character type cannot be coerced into double, these values will be replaced with NA. If you have messy data like this the best thing to do is to force read_csv to read in as character type to preserve all values as they appear, you can then sort out the mess yourself. You can specify the column data type using the col_types argument. Below I have used a compact string of abbreviations (c = character, d = double, D = date, t = time) to specify the column types, see the help at ?read_csv or the {readr} vignette for the full list. You can see I got many parsing failures, which I can access with problems(), which is a data frame of the values that read_csv was unable to coerce into the type I specified, and so has replaced with NA. pokemon &lt;- readr::read_csv( file = &quot;data/messy_pokemon_data.csv&quot; , col_types = &quot;cdddcdcccDt&quot; ) ## Warning: 723 parsing failures. ## row col expected actual file ## 1 date_first_capture date like 31 May 1977 &#39;data/messy_pokemon_data.csv&#39; ## 2 date_first_capture date like 24 February 1973 &#39;data/messy_pokemon_data.csv&#39; ## 3 date_first_capture date like 21 June 1924 &#39;data/messy_pokemon_data.csv&#39; ## 4 date_first_capture date like 01 August 1925 &#39;data/messy_pokemon_data.csv&#39; ## 5 date_first_capture date like 06 August 1952 &#39;data/messy_pokemon_data.csv&#39; ## ... .................. .......... ................ ............................. ## See problems(...) for more details. # c = character, d = double, D = Date, t = time tibble::glimpse(pokemon) ## Observations: 696 ## Variables: 11 ## $ species &lt;chr&gt; &quot;abra&quot;, &quot;abra&quot;, &quot;bellsprout&quot;, &quot;bellsprout&quot;, &quot;… ## $ combat_power &lt;dbl&gt; 101, 81, 156, 262, 389, 433, 628, 161, 135, 4… ## $ hit_points &lt;dbl&gt; 20, 16, 32, 44, 50, 59, 68, 33, 29, 51, 26, 6… ## $ weight_kg &lt;dbl&gt; 17.18, 25.94, 5.85, 5.42, 3.40, 6.67, 3.84, 1… ## $ weight_bin &lt;chr&gt; &quot;normal&quot;, &quot;extra_large&quot;, &quot;extra_large&quot;, &quot;extr… ## $ height_m &lt;dbl&gt; 0.85, 1.00, 0.80, 0.82, 0.66, 0.84, 0.78, 0.3… ## $ height_bin &lt;chr&gt; &quot;normal&quot;, &quot;normal&quot;, &quot;normal&quot;, &quot;normal&quot;, &quot;norm… ## $ fast_attack &lt;chr&gt; &quot;zen_headbutt&quot;, &quot;zen_headbutt&quot;, &quot;acid&quot;, &quot;acid… ## $ charge_attack &lt;chr&gt; &quot;shadow_ball&quot;, &quot;shadow_ball&quot;, &quot;sludge_bomb&quot;, … ## $ date_first_capture &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ time_first_capture &lt;time&gt; 20:59:33, 10:18:40, 08:06:55, 11:18:28, 21:1… Let’s take a look at the problems. problems(pokemon) %&gt;% head() row col expected actual file 1 date_first_capture date like 31 May 1977 ‘data/messy_pokemon_data.csv’ 2 date_first_capture date like 24 February 1973 ‘data/messy_pokemon_data.csv’ 3 date_first_capture date like 21 June 1924 ‘data/messy_pokemon_data.csv’ 4 date_first_capture date like 01 August 1925 ‘data/messy_pokemon_data.csv’ 5 date_first_capture date like 06 August 1952 ‘data/messy_pokemon_data.csv’ 6 date_first_capture date like 17 January 1915 ‘data/messy_pokemon_data.csv’ And since I know that there are problems with combat_power let’s take a look there. problems(pokemon) %&gt;% dplyr::filter(col == &quot;combat_power&quot;) %&gt;% head() row col expected actual file 12 combat_power a double P577 ‘data/messy_pokemon_data.csv’ 96 combat_power a double P458 ‘data/messy_pokemon_data.csv’ 97 combat_power a double P455 ‘data/messy_pokemon_data.csv’ 98 combat_power a double P518 ‘data/messy_pokemon_data.csv’ 99 combat_power a double P348 ‘data/messy_pokemon_data.csv’ 100 combat_power a double P542 ‘data/messy_pokemon_data.csv’ The problems() feature in read_csv is super useful, it helps you isolate the problem data so you can fix it. Other arguments within read_csv that I will just mention, with their default settings are col_names = TRUE: the first row on the input is used as the column names. na = c(&quot;&quot;, &quot;NA&quot;): the default values to interpret as NA. trim_ws = TRUE: by default trims leading/trailing white space. skip = 0: number of lines to skip before reading data. guess_max = min(1000, n_max): maximum number of records to use for guessing column type. NB the bigger this is the longer it will take to read in the data. 3.6 .xlsx and .xls Excel workbooks come in many shapes and sizes. You may have one or many worksheets in one or many workbooks, there may only be certain cells that you are interested in. Below are a few examples of how to cope with these variations using functions from {readxl} and {purrr} to iterate over either worksheets and/or workbooks, the aim being to end up with all the data in a single tidy dataframe. 3.6.1 Single worksheet - single workbook The simplest combination, you are interested in one rectangular dataset in a particular worksheet in one workbook. Leaving the defaults works fine on this dataset. Note that readxl::read_excel detects if the file is .xlsx or .xls and behaves accordingly. readxl::read_excel(path = &quot;data/port0499.xlsx&quot;) %&gt;% head() year polu_majorport polu_region direction cargo_group cargo_category cargo_description tonnage units 2000 Aberdeen Africa (excl. Mediterranean) Inwards Other General Cargo 92 Iron and steel products 1.153177 0 2000 Aberdeen Africa (excl. Mediterranean) Outwards Other General Cargo 92 Iron and steel products 2.406102 0 2000 Aberdeen Africa (excl. Mediterranean) Outwards Other General Cargo 99 Other general cargo &amp; containers &lt;20’ 3.664545 0 2000 Aberdeen America Inwards Other General Cargo 91 Forestry products 108.771082 0 2000 Aberdeen America Inwards Other General Cargo 92 Iron and steel products 11.045082 0 2000 Aberdeen America Outwards Other General Cargo 99 Other general cargo &amp; containers &lt;20’ 12.397106 0 Let’s set a few of the other arguments, run ?read_excel in the console to see the full list. readxl::read_excel( path = &quot;data/port0499.xlsx&quot; , sheet = 1 #number or name of sheet, default is first sheet , col_names = TRUE #default , col_types = &quot;text&quot; #a single type will recycle to all columns, specify each using character vector of the same length eg c(&quot;numeric&quot;, &quot;text&quot;, ...) ) %&gt;% head() year polu_majorport polu_region direction cargo_group cargo_category cargo_description tonnage units 2000 Aberdeen Africa (excl. Mediterranean) Inwards Other General Cargo 92 Iron and steel products 1.15317721340056 0 2000 Aberdeen Africa (excl. Mediterranean) Outwards Other General Cargo 92 Iron and steel products 2.4061025320368699 0 2000 Aberdeen Africa (excl. Mediterranean) Outwards Other General Cargo 99 Other general cargo &amp; containers &lt;20’ 3.6645448610128639 0 2000 Aberdeen America Inwards Other General Cargo 91 Forestry products 108.771081940982 0 2000 Aberdeen America Inwards Other General Cargo 92 Iron and steel products 11.045081750930599 0 2000 Aberdeen America Outwards Other General Cargo 99 Other general cargo &amp; containers &lt;20’ 12.397106259006 0 3.6.2 Single worksheet - many workbooks For example, you collect pokemon go capture data from many different players, the data all has the same structure and you want to read it in and row bind into a single dataframe in R. The code below collects the names of the 3 excel workbooks using fs::dir_ls, and, as these are not the only files in that folder, I’ve specified them using regular expressions (regex). Then we use purrr::map_dfr to iterate and rowbind over this list of files, applying the function we supply, that is readxl::read_excel. Since we are only reading a single worksheet per workbook we don’t need to supply any arguments to readxl:read_excel, the defaults will work fine, each workbook path is piped in, in turn. The .id argument in purrr:map_dfr adds the file path into a new column, which we have named “player” in this instance. The “dfr” in map_dfr refers to the output “data-frame-rowbound”. pokemon &lt;- fs::dir_ls(path = &quot;data&quot;, regex = &quot;pokemon_player_.\\\\.xlsx$&quot;) %&gt;% purrr::map_dfr(.f = readxl::read_excel, .id = &quot;player&quot;) tibble::glimpse(pokemon) ## Observations: 15 ## Variables: 10 ## $ player &lt;chr&gt; &quot;data/pokemon_player_a.xlsx&quot;, &quot;data/pokemon_player… ## $ species &lt;chr&gt; &quot;krabby&quot;, &quot;geodude&quot;, &quot;venonat&quot;, &quot;parasect&quot;, &quot;eevee… ## $ combat_power &lt;dbl&gt; 51, 85, 129, 171, 172, 10, 234, 20, 173, 157, 249,… ## $ hit_points &lt;dbl&gt; 15, 23, 38, 32, 37, 11, 33, 20, 26, 49, 50, 10, 13… ## $ weight_kg &lt;dbl&gt; 5.82, 20.88, 20.40, 19.20, 4.18, 6.21, 73.81, 5.28… ## $ weight_bin &lt;chr&gt; &quot;normal&quot;, &quot;normal&quot;, &quot;extra_small&quot;, &quot;extra_small&quot;, … ## $ height_m &lt;dbl&gt; 0.36, 0.37, 0.92, 0.87, 0.25, 0.36, 1.52, 0.30, 0.… ## $ height_bin &lt;chr&gt; &quot;normal&quot;, &quot;normal&quot;, &quot;normal&quot;, &quot;normal&quot;, &quot;normal&quot;, … ## $ fast_attack &lt;chr&gt; &quot;mud_shot&quot;, &quot;rock_throw&quot;, &quot;confusion&quot;, &quot;bug_bite&quot;,… ## $ charge_attack &lt;chr&gt; &quot;vice_grip&quot;, &quot;rock_tomb&quot;, &quot;poison_fang&quot;, &quot;x-scisso… Using DT::datatable for ease of viewing we can see that all 5 rows of data from each of the 3 workbooks has been read in, rowbound, and an id column has been added showing the workbook path. DT::datatable(data = pokemon) Note that the regex argument in fs::dir_ls is applied to the full file path so if I had tried to specify that the file name starts with “pokemon” by front anchoring it using “^pokemon” this would return no results, since the full name is actually “data/pokemon…”. Helpful regex links below. regex cheatsheet stringr cheatsheet including regex 3.6.3 Many worksheets - single workbook You have a single workbook, but it contains many worksheets of interest, each containing rectangular data with the same structure. For example, you have a workbook containing pokemon go captures data, where each different data collection point has its own sheet. The data structure, column names and data types are consistent. You want to read in and combine these data into a single dataframe. The code below sets the location of the workbook and puts this in the object path. It then collects the names of all the sheets in that workbook using readxl::excel_sheets. Next purrr::set_names sets these names in a vector so that they can be used in the next step. This vector of names is implicitly assigned to the .x argument in purrr::map_dfr as it is the first thing passed to it. This means we can refer to it as .x in the function we are iterating, in this case readxl::read_excel. Finally, an id column is included, made up of the sheet names and named “sheet”. The output is a single dataframe with all the sheets row bound together. path &lt;- &quot;data/multi_tab_messy_pokemon_data.xlsx&quot; pokemon_collections &lt;- readxl::excel_sheets(path = path) %&gt;% purrr::set_names() %&gt;% purrr::map_dfr( ~ readxl::read_excel(path = path, sheet = .x) , .id = &quot;sheet&quot; ) DT::datatable(data = pokemon_collections) 3.6.4 Many worksheets - many workbooks Now we can use the above two solutions to combine data from many worksheets spread across many workbooks. As before, the data is rectangular and has the same structure. For example, you receive a workbook every month, containing pokemon go captures data, and each data collection point has its own sheet. We create a function to import and combine the sheets from a single workbook, and then iterate this function over all the workbooks using purrr::map_df. #function to combine sheets from a single workbook read_and_combine_sheets &lt;- function(path){ readxl::excel_sheets(path = path) %&gt;% purrr::set_names() %&gt;% purrr::map_df( ~ readxl::read_excel(path = path, sheet = .x) , .id = &quot;sheet&quot; ) } #code to iterate over many workbooks pokemon_monthly_collections &lt;- fs::dir_ls( path = &quot;data&quot;, regex = &quot;pokemon_2019\\\\d{2}\\\\.xlsx$&quot;) %&gt;% purrr::map_df( read_and_combine_sheets , .id = &quot;month&quot; ) DT::datatable(data = pokemon_monthly_collections) 3.6.5 Non-rectangular data - single worksheet - single workbook You have received some kind of data entry form that has been done in excel in a more human readable, rather than machine readable, format. Some of the cells contain instructions and admin data so you only want the data held in specific cells. This is non-rectangular data, that is, the data of interest is dotted all over the place. In this example we have pet forms, and the data of interest is in cells B2, D5 and E8 only. Here’s an image of what the data looks like. Let’s see what we get if we naively try to read it in. readxl::read_excel( path = &quot;data/pet_form_1.xlsx&quot; ) %&gt;% knitr::kable() %&gt;% kableExtra::kable_styling(full_width = F, position = &quot;left&quot;) Name: Tiddles …3 …4 …5 NA NA NA NA NA NA NA NA NA NA NA NA Age: 2 NA NA NA NA NA NA NA NA NA NA NA NA NA NA Species: cat It’s not what we wanted, let’s try again, now using the range argument readxl::read_excel( path = &quot;data/pet_form_1.xlsx&quot; , col_names = FALSE , range = &quot;A2:B2&quot; ) %&gt;% knitr::kable() %&gt;% kableExtra::kable_styling(full_width = F, position = &quot;left&quot;) …1 …2 Name: Tiddles The range argument helps, we have picked up one bit of the data, and its name. The range argument uses the {cellranger} package which allows you to refer to ranges in Excel files in Excel style. However, we have 3 disconnected data points, we need to iterate, so it’s {purrr} to the rescue once more. The code below demonstrates explicitly that the .x argument in purrr::map_dfr takes the vector of things that will be iterated over in the supplied function. In this case we are giving the range argument of readxl::read_excel three individual cells to iterate over. These will then be rowbound so we end up with a single dataframe comprising a single column, named “cells”, containing 3 rows. pet_details &lt;- purrr::map_dfr( .x = c(&quot;B2&quot;, &quot;D5&quot;, &quot;E8&quot;) , ~ readxl::read_excel( path = &quot;data/pet_form_1.xlsx&quot; , range = .x , col_names = &quot;cells&quot; #assign name , col_types = &quot;text&quot; #have to use text to preserve all data in single column ) ) pet_details %&gt;% knitr::kable() %&gt;% kableExtra::kable_styling(full_width = F, position = &quot;left&quot;) cells Tiddles 2 cat This is an improvement, we have a dataframe named pet_details comprising a single “cells” column, which contains all the relevant data from this worksheet. We could now try to reshape it, however, a better idea is to use map_dfc since we actually want to column bind these data rather than rowbind them. The read out from tibble::glimpse shows that the different variable types have been picked up, which is also helpful. The default naming of the columns gives a clue as to how the function works. pet_details &lt;- purrr::map_dfc( .x = c(&quot;B2&quot;, &quot;D5&quot;, &quot;E8&quot;) #vector of specific cells containing the data , ~ readxl::read_excel( path = &quot;data/pet_form_1.xlsx&quot; , range = .x , col_names = FALSE ) ) ## New names: ## * `` -&gt; ...1 ## New names: ## * `` -&gt; ...1 ## New names: ## * `` -&gt; ...1 tibble::glimpse(pet_details) ## Observations: 1 ## Variables: 3 ## $ ...1 &lt;chr&gt; &quot;Tiddles&quot; ## $ ...11 &lt;dbl&gt; 2 ## $ ...12 &lt;chr&gt; &quot;cat&quot; …1 …11 …12 Tiddles 2 cat This is pretty close to what we want, the only sticking point is that we still don’t have the correct column names. We could deal with this using dplyr::rename, but an even better idea is to use purrr::map2_dfc. The map2 variant allows you to iterate over two arguments simultaneously (into the same function). pet_details_2 &lt;- purrr::map2_dfc( .x = c(&quot;B2&quot;, &quot;D5&quot;, &quot;E8&quot;) #vector of specific data cells , .y = c(&quot;Name&quot;, &quot;Age&quot;, &quot;Species&quot;) #vector of column names , ~ readxl::read_excel( path = &quot;data/pet_form_1.xlsx&quot; , range = .x , col_names = .y ) ) tibble::glimpse(pet_details_2) ## Observations: 1 ## Variables: 3 ## $ Name &lt;chr&gt; &quot;Tiddles&quot; ## $ Age &lt;dbl&gt; 2 ## $ Species &lt;chr&gt; &quot;cat&quot; Name Age Species Tiddles 2 cat 3.6.6 Non-rectangular data - single worksheet - many workbooks Having solved for one workbook and worksheet, we can functionalise and iterate to gather the data from every workbook, two of which are shown below. The function cells_to_rows below iterates over read_excel reading each of the three cells from the worksheet, applying the corresponding column name as it goes. It takes three character or character vector inputs, path, cells, and col_names. cells_to_rows &lt;- function(path, cells, col_names){ purrr::map2_dfc( .x = cells , .y = col_names , ~ readxl::read_excel( path = path , range = .x , col_names = .y ) ) } Let’s test it on the first pet form data, first setting the parameters to use in the function. path &lt;- &quot;data/pet_form_1.xlsx&quot; cells &lt;- c(&quot;B2&quot;, &quot;D5&quot;, &quot;E8&quot;) col_names &lt;- c(&quot;Name&quot;, &quot;Age&quot;, &quot;Species&quot;) pet_form_1 &lt;- cells_to_rows( path = path, cells = cells, col_names = col_names ) Name Age Species Tiddles 2 cat It works! So now we can iterate this over all the pet form workbooks, specifying the paths using regex as before. Note below we use .x in the path argument in the cells_to_rows function to refer to the vector of paths piped to purrr::map_dfr from fs::dir_ls. cells &lt;- c(&quot;B2&quot;, &quot;D5&quot;, &quot;E8&quot;) col_names &lt;- c(&quot;Name&quot;, &quot;Age&quot;, &quot;Species&quot;) all_pet_forms &lt;- fs::dir_ls( path = &quot;data&quot;, regex = &quot;pet_form_\\\\d\\\\.xlsx$&quot;) %&gt;% purrr::map_dfr( ~ cells_to_rows(path = .x, cells = cells, col_names = col_names) , .id = &quot;path&quot; ) path Name Age Species data/pet_form_1.xlsx Tiddles 2.0 cat data/pet_form_2.xlsx Woof 1.0 dog data/pet_form_3.xlsx Hammy 0.5 hamster data/pet_form_4.xlsx Toothless 3.0 dragon 3.6.7 Non-rectangular data - many worksheets - single workbook Now we have more than one worksheet in a single workbook, and the data looks like this, the workbook is from a “pet house” and each worksheet is pet details. To incorporate the worksheets element we rejig the cells_to_rows function from above and give it a “sheet” argument, so it can be passed a specific sheet. sheet_cells_to_rows &lt;- function(path, sheet, cells, col_names){ purrr::map2_dfc( .x = cells , .y = col_names , ~ readxl::read_excel( path = path , sheet = sheet , range = .x , col_names = .y ) ) } We now have the function sheet_cells_to_rows that can accept a list of worksheet names. As before we use readxl::excel_sheets to collect the worksheet names, first setting the other parameters path &lt;- &quot;data/pet_house_1.xlsx&quot; cells &lt;- c(&quot;B2&quot;, &quot;D5&quot;, &quot;E8&quot;) col_names &lt;- c(&quot;Name&quot;, &quot;Age&quot;, &quot;Species&quot;) pet_house_1 &lt;- readxl::excel_sheets(path = path) %&gt;% purrr::set_names() %&gt;% purrr::map_dfr( ~ sheet_cells_to_rows(path = path , sheet = .x , cells = cells , col_names = col_names) , .id = &quot;sheet&quot; ) 3.6.8 Non-rectangular data - many worksheets - many workbooks Finally we have many workbooks each containing many worksheets, each containing many cells, as before we want to read them in and combine. We could functionalise the code above that reads and combines the cells in many worksheets from a single workbook, but an alternative approach is used below. We create an anonymous function and use that on the fly. This is useful if the function is a one off, and not too complicated. The anonymous function below still depends on the sheet_cells_to_rows we created earlier though. cells &lt;- c(&quot;B2&quot;, &quot;D5&quot;, &quot;E8&quot;) col_names &lt;- c(&quot;Name&quot;, &quot;Age&quot;, &quot;Species&quot;) pet_house_all &lt;- fs::dir_ls( path = &quot;data&quot;, regex = &quot;pet_house_\\\\d\\\\.xlsx$&quot;) %&gt;% purrr::map_dfr( function(path){ readxl::excel_sheets(path = path) %&gt;% purrr::set_names() %&gt;% purrr::map_dfr( ~ sheet_cells_to_rows(path = path , sheet = .x , cells = cells , col_names = col_names) , .id = &quot;sheet&quot; ) } , .id = &quot;path&quot; ) path sheet Name Age Species data/pet_house_1.xlsx pet_1 Tiddles 2.0 cat data/pet_house_1.xlsx pet_2 Leafy 0.8 shield bug data/pet_house_2.xlsx pet_1 Tuuli 8.0 tiger data/pet_house_2.xlsx pet_2 Sophie 4.0 cheetah data/pet_house_2.xlsx pet_3 Pearl 3.0 Chilean rose tarantula 3.7 Exporting to .xlsx We recommend {openxlsx} and {xltabr} for writing and formatting tables to MS Excel. The latter is a wrapper built on {openxlsx} developed by MoJ and is specifically aimed at making it easier to produce publication ready tables. {xltabr} has one known drawback in that it applies the formatting cell by cell, so if your tables are massive (~100,000 rows) it will take too long, in this instance you should resort to {openxlsx}. openxlsx manual xltabr manual So you can see an example of the formatting available, here is a link to DfT’s Search and Rescue Helicopter (SARH) statistics tables that are produced in R using {xltabr}. SARH tables 3.8 .sav Use {haven} to import SPSS, Stata and SAS files. 3.9 SQL Below are links to DfT Coffee and Coding materials on the subject of connecting R to SQL 20181114_Connecting_R_to_SQL 20190130_SQL_and_Excel_to_R 3.10 GCP 3.10.1 BigQuery Link below to DfT Coffee and Coding materials on how to use {bigrquery} to interact with GCP’s BigQuery 20190403_bigrquery "],
["tables.html", "Chapter 4 Table/Data Frame manipulation 4.1 Pivot and reshape tables 4.2 Dropping and selecting columns 4.3 Filtering data 4.4 Group data 4.5 Order data 4.6 Get counts of data 4.7 Combine tables 4.8 Joining tables 4.9 Select specific columns in a join 4.10 Sum rows or columns 4.11 Replace NAs or other values 4.12 Reordering rows/columns 4.13 Creating new variables 4.14 Summarising data 4.15 Look up tables", " Chapter 4 Table/Data Frame manipulation This chapter provides an overview of code examples for table or data frame manipulation (a tidyverse data frame is referred to as a tibble). One of the main things you will have to do in any R project or RAP project will be manipulating the data that you are using in order to get it into the format you require. One of the main packages used to manipulate data is the {dplyr} package which we recommend and use throughout this book. The {dplyr} package (and others e.g. {tidyr}) are all part of the tidyverse. The tidyverse is a group of packages developed by Hadley Wickham and others and are all designed to work with each other. See https://www.tidyverse.org/ for more info. Tidyverse packages and functions can be combined and layered using the pipe operator %&gt;%. {dplyr} is built to work with tidy data. To find out more about tidy data please look at the following link https://r4ds.had.co.nz/tidy-data.html but the general principles are: Each variables must have its own column Each observation must have its own row Each value must have its own cell 4.1 Pivot and reshape tables There will be two examples for pivoting tables provided: The {tidyr} package uses the gather/spread functions and is often used to create tidy data The {reshape2} package is also a useful package to pivot tables and has added functionality such as providing totals of columns etc. We want to have the day of the week variable running along the top so each day of the week is its own column. Table 4.1: Number of road accidents by accident severity and weekday Accident_Severity Day_of_Week n 1 1 300 1 2 205 1 3 187 1 4 233 1 5 220 1 6 250 {tidyr} package Using the {tidyr} package, gather and spread functions can be used to pivot the table views: gather makes wide data longer i.e. variables running along the top can be “gathered” into rows running down. spread makes long data wider i.e. one variable can be spread and run along the top with each value being a variable. Note: Hadley Wickham is bringing out new versions of these packages called pivot_longer and pivot_wider which are not yet available on DfT laptops. # Pivot table using tidyr package library(tidyr) road_accidents_weekdays &lt;- road_accidents_small %&gt;% tidyr::spread(Day_of_Week, n) With the spread function above you need to first specify the variable you want to spread, in this case Day_of_Week, and then the variable that will be used to populate the columns (n). Table 4.2: Number of road accidents by accident severity and weekday, tidyr::spread Accident_Severity 1 2 3 4 5 6 7 1 300 205 187 233 220 250 281 2 3009 2948 3230 3227 3246 3649 3225 3 11668 14783 16065 15859 16331 17346 13720 The opposite can also be done using the gather function: # Pivot table using tidyr package library(tidyr) road_accidents_gather &lt;- road_accidents_weekdays %&gt;% tidyr::gather(`1`, `2`, `3`, `4`, `5`, `6`, `7`, key = &quot;weekday&quot;, value = &quot;n&quot;) To use gather, specify which columns you want to be gathered into one column (in this case the individual weekday columns). The key is the name of the gathered column, and the value is the name of the values. Table 4.3: Number of road accidents by accident severity and weekday, tidyr::gather Accident_Severity weekday n 1 1 300 2 1 3009 3 1 11668 1 2 205 2 2 2948 3 2 14783 {reshape2} package Again, this has two functions which can be used to pivot tables: melt makes wide data longer dcast makes long data wider # Pivot table using reshape2 package library(reshape2) road_accidents_weekdays2 &lt;- reshape2::dcast(road_accidents_small, Accident_Severity ~ Day_of_Week, value.var = &quot;n&quot;) With the dcast function above, after stating the name of the data frame, you need to specify the variable(s) you want in long format (multiple variables seperated by “+”), in this case Accident_Severity, and then the wide format variable(s) are put after the tilda (again multiple seperated by “+”). The value.var argument specifies which column will be used to populate the new columns, in this case it is n. Table 4.4: Number of road accidents by accident severity and weekday, reshape2::dcast Accident_Severity 1 2 3 4 5 6 7 1 300 205 187 233 220 250 281 2 3009 2948 3230 3227 3246 3649 3225 3 11668 14783 16065 15859 16331 17346 13720 If you want to create sums and totals of the tables this can also be done using {reshape2}. For example, taking the original table, we want to pivot it and sum each severity to get the total number of accidents per day. # Pivot table using reshape2 package library(reshape2) road_accidents_weekdays3 &lt;- reshape2::dcast(road_accidents_small, Accident_Severity ~ Day_of_Week, value.var = &quot;n&quot;, sum, margins = &quot;Accident_Severity&quot;) In this example, we use the margins argument to specify what we want to combine to create totals. So we want to add all the accident severity figures up for each weekday. Before using margins you need to specify how the margins are calculated, in this case we want a sum. Alternative options are to calculate the length, i.e. the number of rows. Table 4.5: Number of road accidents by accident severity and weekday plus totals, reshape2::dcast Accident_Severity 1 2 3 4 5 6 7 1 300 205 187 233 220 250 281 2 3009 2948 3230 3227 3246 3649 3225 3 11668 14783 16065 15859 16331 17346 13720 (all) 14977 17936 19482 19319 19797 21245 17226 The opposite can also be done using the melt function. # Pivot table using reshape2 package library(reshape2) road_accidents_melt &lt;- reshape2::melt(road_accidents_weekdays2, id.vars = &quot;Accident_Severity&quot;, measure.vars = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;), variable.name = &quot;Day_of_Week&quot;, value.name = &quot;n&quot;) For the melt function you need to specify: id.vars = “variables to be kept as columns” measure.vars = c(“variables to be created as one column”) variable.name = “name of created column using the measure.vars” value.name = “name of value column” Table 4.6: Number of road accidents by accident severity and weekday, reshape2::melt Accident_Severity Day_of_Week n 1 1 300 2 1 3009 3 1 11668 1 2 205 2 2 2948 3 2 14783 4.2 Dropping and selecting columns Use the {dplyr} select function to both select and drop columns. Select columns road_accidents_4_cols &lt;- road_accidents %&gt;% dplyr::select(acc_index, Accident_Severity, Date, Police_Force) Table 4.7: Four columns from road accidents 2017 acc_index Accident_Severity Date Police_Force 2017010001708 1 2017-08-05 1 2017010009342 3 2017-01-01 1 2017010009344 3 2017-01-01 1 2017010009348 3 2017-01-01 1 2017010009350 2 2017-01-01 1 2017010009351 3 2017-01-01 1 Drop columns Note that to drop columns the difference is putting a “-” in front of the variable name. road_accidents_3_cols &lt;- road_accidents_4_cols %&gt;% dplyr::select(-Police_Force) Table 4.8: Three columns from road accidents 2017 acc_index Accident_Severity Date 2017010001708 1 2017-08-05 2017010009342 3 2017-01-01 2017010009344 3 2017-01-01 2017010009348 3 2017-01-01 2017010009350 2 2017-01-01 2017010009351 3 2017-01-01 4.3 Filtering data Use the {dplyr} filter function to filter data. This example filters the data for slight severity accidents (accident severity 3). road_accidents_slight &lt;- road_accidents_4_cols %&gt;% dplyr::filter(Accident_Severity == 3) Table 4.9: Slight severity road accidents 2017 acc_index Accident_Severity Date Police_Force 2017010009342 3 2017-01-01 1 2017010009344 3 2017-01-01 1 2017010009348 3 2017-01-01 1 2017010009351 3 2017-01-01 1 2017010009353 3 2017-01-01 1 2017010009354 3 2017-01-01 1 To filter multiple conditions: And operator road_accidents_filter &lt;- road_accidents_4_cols %&gt;% dplyr::filter(Accident_Severity == 3 &amp; Police_Force == 4) Or operator road_accidents_filter2 &lt;- road_accidents_4_cols %&gt;% dplyr::filter(Accident_Severity == 3 | Accident_Severity == 2) Note: filtering with characters must be wrapped in “quotation marks” e.g: road_accidents_filter3 &lt;- road_accidents %&gt;% dplyr::filter(`Local_Authority_(Highway)` == &quot;E09000010&quot;) Also note that in the above example the variable is quoted in back ticks (`). This is because some variable names confuse R due to brackets and numbers and need to be wrapped in back ticks so R knows that everything inside the back ticks is a variable name. 4.4 Group data Use the {dplyr} group_by function to group data. This works in a similar manner to “GROUP BY” in SQL. The below example groups the data by accident severity and weekday, and creates totals for each group using the “tally” function. # Create grouped data set with counts road_accidents_small &lt;- road_accidents %&gt;% dplyr::group_by(Accident_Severity, Day_of_Week) %&gt;% dplyr::tally() Table 4.10: Road accidents 2017 by accident severity and weekday Accident_Severity Day_of_Week n 1 1 300 1 2 205 1 3 187 1 4 233 1 5 220 1 6 250 4.5 Order data Use the {dplyr} arrange function to order data. This works in a similar manner to “ORDER BY” in SQL. This example orders the data by date and number of casualties. # Order data by date and number of casualties road_accidents_ordered &lt;- road_acc_7 %&gt;% dplyr::select(acc_index, Accident_Severity, Police_Force, Number_of_Casualties, Date) %&gt;% dplyr::arrange(Date, Number_of_Casualties) Table 4.11: Road accidents 2017 ordered by date and number of casualties acc_index Accident_Severity Police_Force Number_of_Casualties Date 2017140147352 3 14 2 2017-01-16 2017140163613 3 14 1 2017-03-02 2017010030548 3 1 1 2017-04-06 2017950002111 3 95 1 2017-09-29 2017077360629 3 7 1 2017-11-08 2017471706377 3 47 1 2017-11-12 4.6 Get counts of data To get counts for groups of data, the {dplyr} tally function can be used in conjunction with the {dplyr} group by function. This groups the data into the required groups and then tallys how many records are in each group. # Create grouped data set with counts road_accidents_small &lt;- road_accidents %&gt;% dplyr::group_by(Accident_Severity, Day_of_Week) %&gt;% dplyr::tally() The above example creates groups by accident severity and weekday and counts how many accidents are in each group (one row equals one accident therefore the tally is counting accidents). Table 4.12: Road accidents 2017 by accident severity and weekday Accident_Severity Day_of_Week n 1 1 300 1 2 205 1 3 187 1 4 233 1 5 220 1 6 250 4.7 Combine tables When combining data from two tables there are two ways to do this in R: Bind the tables by basically either appending the tables on the rows or columns Join the tables using the {dplyr} version of SQL joins Binding tables Binding tables is mainly done to append tables by creating more rows, however tables can also be bound by adding more columns. Although it is recommended to use the {dplyr} join functions to combine columns (see 5.6). Here are three tables, one shows data for accident severity of 1, one for accident severity of 2, and one for accident severity of 3. Table 4.13: Number of fatal road accidents in 2017, by weekday Accident_Severity Day_of_Week n 1 1 300 1 2 205 1 3 187 1 4 233 1 5 220 1 6 250 1 7 281 Table 4.13: Number of serious injury road accidents in 2017, by weekday Accident_Severity Day_of_Week n 2 1 3009 2 2 2948 2 3 3230 2 4 3227 2 5 3246 2 6 3649 2 7 3225 Table 4.13: Number of slight injury road accidents in 2017, by weekday Accident_Severity Day_of_Week n 3 1 11668 3 2 14783 3 3 16065 3 4 15859 3 5 16331 3 6 17346 3 7 13720 To combine these tables we can use the bind_rows function from the {dplyr} package. Use bind_rows when you want to append the tables underneath one another to make one longer table, i.e. you want to add more rows. Ensure that the column names for each table are exactly the same in each table. # combine tables using bind_rows library(dplyr) all_accidents &lt;- accidents_1 %&gt;% dplyr::bind_rows(accidents_2, accidents_3) Table 4.14: Road accident data 2017, bind_rows Accident_Severity Day_of_Week n 1 1 300 1 2 205 1 3 187 1 4 233 1 5 220 1 6 250 1 7 281 2 1 3009 2 2 2948 2 3 3230 2 4 3227 2 5 3246 2 6 3649 2 7 3225 3 1 11668 3 2 14783 3 3 16065 3 4 15859 3 5 16331 3 6 17346 3 7 13720 4.8 Joining tables Joins in R can be done using {dplyr}. This is generally to combine columns of data from two tables: # combine tables using left join library(dplyr) all_accidents_cols_join &lt;- road_acc_1 %&gt;% dplyr::left_join(road_acc_2, by = &quot;acc_index&quot;) This uses the same principles as SQL, by specifying what the tables should be joined on using the by = argument. {dplyr} has all the usual SQL joins for example, inner_join, full_join, right_join. All of these are used in the same way as the left join example above. Another useful join for data manipulation is an anti_join. This provides all the data that is not in the joined table. For example, the below snapshot of a table displays road accident totals broken down by accident severity and weekday: Accident_Severity Day_of_Week n 1 1 300 1 2 205 1 3 187 1 4 233 1 5 220 1 6 250 I am interested in creating two sub-groups of this data, a table for all accidents on a Monday (weekday 2), and all other accidents. First, I get the Monday data using the {dplyr} filter function (see 5.3). Accident_Severity Day_of_Week n 1 2 205 2 2 2948 3 2 14783 Then, I can use an anti-join to create a table which has all of the data that is not in the above table: # create table of all rows not in the joined table library(dplyr) all_accidents_not_monday &lt;- road_accidents_small %&gt;% dplyr::anti_join(accidents_monday, by = c(&quot;Accident_Severity&quot;, &quot;Day_of_Week&quot;)) The above code takes the initial table we want to get our data from (road_accidents_small) and anti joins accidents_monday. This says, “get all the rows from road_accidents_small that are not in accidents_monday”. Again, note the need to specify what the join rows would be joined and compared by. Table 4.15: Road accident data 2017 not on a Monday by accident severity Accident_Severity Day_of_Week n 1 1 300 1 3 187 1 4 233 1 5 220 1 6 250 1 7 281 2 1 3009 2 3 3230 2 4 3227 2 5 3246 2 6 3649 2 7 3225 3 1 11668 3 3 16065 3 4 15859 3 5 16331 3 6 17346 3 7 13720 4.9 Select specific columns in a join Doing a join with {dplyr} will join all columns from both tables, however sometimes not all columns from each table are needed. Let’s look at some previous tables again: Table 4.16: Police force and accident severity information for accidents acc_index Police_Force Accident_Severity 2017010001708 1 1 2017010009342 1 3 2017010009344 1 3 2017010009348 1 3 2017010009350 1 2 2017010009351 1 3 Table 4.16: Date and weekday information for accidents acc_index Date Day_of_Week 2017010001708 2017-08-05 7 2017010009342 2017-01-01 1 2017010009344 2017-01-01 1 2017010009348 2017-01-01 1 2017010009350 2017-01-01 1 2017010009351 2017-01-01 1 Let’s say we want acc_index and Police_Force from the first table, and Date from the second table. # select specific columns from each table and left join library(dplyr) road_acc_3 &lt;- road_acc_1 %&gt;% dplyr::select(acc_index, Police_Force) %&gt;% dplyr::left_join(select(road_acc_2, acc_index, Date), by = &quot;acc_index&quot;) The above code takes the first table and uses the select statement to select the required columns from the first table. Then within the left_join command, to select the data from the second table, you again add the select statement. Note: you will need to select the joining variable in both tables but this will only appear once Table 4.17: Police force and Date information for specific accidents acc_index Police_Force Date 2017010001708 1 2017-08-05 2017010009342 1 2017-01-01 2017010009344 1 2017-01-01 2017010009348 1 2017-01-01 2017010009350 1 2017-01-01 2017010009351 1 2017-01-01 4.10 Sum rows or columns These solutions use the base R functions rather than {dplyr}. 4.10.1 Sum rows To sum across a row: # sum across a row road_accidents_weekdays$rowsum &lt;- rowSums(road_accidents_weekdays, na.rm = TRUE) Table 4.18: Road accidents 2017 by accident severity and weekday Accident_Severity 1 2 3 4 5 6 7 rowsum 1 300 205 187 233 220 250 281 1677 2 3009 2948 3230 3227 3246 3649 3225 22536 3 11668 14783 16065 15859 16331 17346 13720 105775 To sum across specific rows: # sum across specific rows road_accidents_weekdays$alldays &lt;- road_accidents_weekdays$`1` + road_accidents_weekdays$`2`+ road_accidents_weekdays$`3`+ road_accidents_weekdays$`4`+ road_accidents_weekdays$`5`+ road_accidents_weekdays$`6`+ road_accidents_weekdays$`7` Table 4.19: Road accidents 2017 by accident severity and weekday Accident_Severity 1 2 3 4 5 6 7 alldays 1 300 205 187 233 220 250 281 1676 2 3009 2948 3230 3227 3246 3649 3225 22534 3 11668 14783 16065 15859 16331 17346 13720 105772 4.10.2 Sum columns To sum columns to get totals of each column, note this will appear as a console output not in a data object: # sum columns colSums(road_accidents_weekdays, na.rm = TRUE) To get the totals of each column as a row in the data: # create total column road_accidents_weekdays &lt;- road_accidents_weekdays %&gt;% janitor::adorn_totals(&quot;row&quot;) Table 4.20: Road accidents 2017 by accident severity and weekday Accident_Severity 1 2 3 4 5 6 7 1 300 205 187 233 220 250 281 2 3009 2948 3230 3227 3246 3649 3225 3 11668 14783 16065 15859 16331 17346 13720 Total 14977 17936 19482 19319 19797 21245 17226 {reshape2} can also be used to get column totals when pivoting a table (See 5.1). 4.11 Replace NAs or other values To replace all NAs in one column (Junction Control column) with a specific value: library (tidyr) # replace all NAs with value -1 road_accidents_na$Junction_Control &lt;- road_accidents_na$Junction_Control %&gt;% tidyr::replace_na(-1) Note: To replace NA with a character the character replacement must be wrapped in “quotation marks” To replace all NAs in a data frame or tibble: # replace all NAs with value -1 road_accidents_na &lt;- road_accidents_na %&gt;% replace(is.na(.), -1) To replace values with NA, specify what value you want to be replaced with NA using the na_if function: # create nas road_accidents_na &lt;- road_accidents_na %&gt;% dplyr::na_if(-1) Note: to only create NAs in a specific column specify the column name in a similar manner to the first example in this section. To replace values: # replace 1st_road_class road_accidents_na &lt;- road_accidents_na %&gt;% dplyr::mutate(`1st_Road_Class` = dplyr::case_when(`1st_Road_Class` == 3 ~ &quot;A Road&quot;, TRUE ~ as.character(`1st_Road_Class`))) The case_when function is similar to using CASE WHEN in SQL. The TRUE argument indicates that if the values aren’t included in the case_when then they should be whatever is after the tilda (~) i.e. the equivalent of the ELSE statement in SQL. The “as.character” function says that everything that in 1st_Road_Class isn’t 3 should be kept as it is, this could be replaced by an arbitrary character or value e.g. “Other”. This would make everything that is not a 3, coded as “Other”. You can have multiple case_when arguments for multiple values, they just need to be seperated with a comma. Multiple case_when statements for different variables can be layered using the pipe operator %&gt;%. 4.12 Reordering rows/columns 4.12.1 Reordering rows Rows can be reordered by certain variables using the {dplyr} arrange function with examples in the 4.5 Order data sub-chapter of this book. This will order the data in ascending order by the variables quoted. To order rows in descending order the desc() command can be used within the arrange function. # Order data by date and number of casualties road_accidents_ordered_desc &lt;- road_acc_7 %&gt;% dplyr::select(acc_index, Accident_Severity, Police_Force, Number_of_Casualties, Date) %&gt;% dplyr::arrange(desc(Date), Number_of_Casualties) Table 4.21: Road accidents 2017 ordered by date (descending) and number of casualties acc_index Accident_Severity Police_Force Number_of_Casualties Date 2017430376489 3 43 1 2017-12-13 2017471706377 3 47 1 2017-11-12 2017077360629 3 7 1 2017-11-08 2017950002111 3 95 1 2017-09-29 2017010030548 3 1 1 2017-04-06 2017140163613 3 14 1 2017-03-02 4.12.2 Reordering columns Use the {dplyr} select statement to reorder columns, where the order of the variables quoted represents the order of the columns in the table. Table 4.22: Four columns from road accidents 2017 acc_index Accident_Severity Date Police_Force 2017010001708 1 2017-08-05 1 2017010009342 3 2017-01-01 1 2017010009344 3 2017-01-01 1 2017010009348 3 2017-01-01 1 2017010009350 2 2017-01-01 1 2017010009351 3 2017-01-01 1 To reorder this table we do: table_reordered &lt;- road_accidents_4_cols %&gt;% dplyr::select(Accident_Severity, Date, acc_index, Police_Force) 4.13 Creating new variables The {dplyr} mutate function can be used to create new variables based on current variables or other additional information. For example, to create a new variable which is speed limit in km: road_acc_km &lt;- road_acc_7 %&gt;% dplyr::mutate(speed_km = Speed_limit * 1.6) Table 4.23: Road accidents by km/h acc_index Police_Force Speed_limit speed_km 2017430376489 43 40 64 2017471706377 47 30 48 2017140147352 14 30 48 2017140163613 14 30 48 2017010030548 1 30 48 2017950002111 95 30 48 4.14 Summarising data The {dplyr} summarise function can be used to summarise data (mean, median, sd, min, max, n_distinct). See https://dplyr.tidyverse.org/reference/summarise.html for more examples. For example, to get the mean number of accidents for each weekday: Table 4.24: Road accidents 2017, by severity and weekday Accident_Severity Day_of_Week n 1 1 300 1 2 205 1 3 187 1 4 233 1 5 220 1 6 250 The group by function is used with the summarise function to specify what groups the mean will be applied to, in this case weekday. road_acc_mean &lt;- road_accidents_small %&gt;% dplyr::group_by(Day_of_Week) %&gt;% dplyr::summarise(mean = mean(n)) Table 4.25: Mean number of accidents in 2017, by weekday Day_of_Week mean 1 4992.333 2 5978.667 3 6494.000 4 6439.667 5 6599.000 6 7081.667 4.15 Look up tables Aside from importing a separate lookup data file into R, named vectors can be used as lookup tables. For example, to assign accident severity values with labels, named vectors can be used (note: numbers must also be in quotation marks): lookup_severity &lt;- c(&quot;1&quot; = &quot;Fatal&quot;, &quot;2&quot; = &quot;Serious&quot;, &quot;3&quot; = &quot;Slight&quot;) To convert the data and create a label variable (note: the Accident_Severity variable values can be replaced with the lookup values by changing the name of the variable on the left to Accident_Severity): road_accidents_small$Accident_Severity_label &lt;- lookup_severity[road_accidents_small$Accident_Severity] Table 4.26: Road accidents 2017, by severity and weekday Accident_Severity Day_of_Week n Accident_Severity_label 1 1 300 Fatal 1 2 205 Fatal 1 3 187 Fatal 1 4 233 Fatal 1 5 220 Fatal 1 6 250 Fatal "],
["dates-times.html", "Chapter 5 Working with dates and times 5.1 Working with dates 5.2 Working with date-times", " Chapter 5 Working with dates and times This chapter provides an overview of working with dates and times, for example extracting year or month from a date, and converting characters to a date. One of the main packages used to work with dates is {lubridate}. More information can be found on the {lubridate} cheatsheet at the following link: https://www.rstudio.com/resources/cheatsheets/ Date vectors are just double vectors with an additional class attribute set as “Date”. Note - The following borrows directly from Hadley’s Advanced R site so we need to attribute appropriately and use correct licence today &lt;- Sys.Date() typeof(today) #&gt; [1] &quot;double&quot; attributes(today) #&gt; $class #&gt; [1] &quot;Date&quot; The value of the double (which can be seen by stripping the class), represents the number of days since “1970-01-01”3: date &lt;- as.Date(&quot;1970-02-01&quot;) unclass(date) #&gt; [1] 31 This chapter will be using the road accident data set: Table 5.1: Reported Road Accidents, 2017 acc_index Date Police_Force Day_of_Week Time 2017010001708 2017-08-05 1 7 1899-12-31 03:12:00 2017010009342 2017-01-01 1 1 1899-12-31 01:30:00 2017010009344 2017-01-01 1 1 1899-12-31 00:30:00 2017010009348 2017-01-01 1 1 1899-12-31 01:11:00 2017010009350 2017-01-01 1 1 1899-12-31 01:42:00 2017010009351 2017-01-01 1 1 1899-12-31 03:31:00 5.1 Working with dates 5.1.1 Converting a character to a date In R, dates can be converted to a specific date variable type in order to use the variable as a date. Having a variable as a date means that you can: extract the different elements of the date (year, month etc.) calculate differences between dates This can be done in the following way: Identify the order of the year, month, day and use the appropriate function (ymd, mdy, dmy etc.) # convert date to date object # check class of date class(road_accidents$Date1) #&gt; [1] &quot;character&quot; # look at the date variable and see what order it is in (year-m-d) # therefore use the ymd function road_accidents$Date1 &lt;- lubridate::ymd(road_accidents$Date1) # now check class class(road_accidents$Date1) #&gt; [1] &quot;Date&quot; 5.1.2 Get year from date Use the year function from {lubridate}: road_accidents$Year &lt;- lubridate::year(road_accidents$Date1) See Table 5.2 for output 5.1.3 Get month from date Use the month function from {lubridate}: road_accidents$Month &lt;- lubridate::month(road_accidents$Date1) See Table 5.2 for output 5.1.4 Get day from date Use the day function from {lubridate}: road_accidents$Day &lt;- lubridate::day(road_accidents$Date1) See Table 5.2 for output 5.1.5 Get weekday from date Use the wday function from {lubridate} to get the weekday label: road_accidents$weekday &lt;- lubridate::wday(road_accidents$Date1) See Table 5.2 for output 5.1.6 Get quarter from date Use the quarter function from {lubridate}: road_accidents$Quarter &lt;- lubridate::quarter(road_accidents$Date1) See Table 5.2 for output Table 5.2: Using lubridate to extract time information Date1 Year Quarter Month Day weekday 2017-08-05 2017 3 8 5 7 2017-01-01 2017 1 1 1 1 2017-01-01 2017 1 1 1 1 2017-01-01 2017 1 1 1 1 2017-01-01 2017 1 1 1 1 2017-01-01 2017 1 1 1 1 5.1.7 Find difference between two dates Table 5.3: Find difference between two dates acc_index Date1 Date2 2017010001708 2017-08-05 2017-08-01 2017010009342 2017-01-01 2017-01-01 2017010009344 2017-01-01 2017-01-01 2017010009348 2017-01-01 2017-01-01 2017010009350 2017-01-01 2017-01-01 2017010009351 2017-01-01 2017-01-01 Use the as.duration function to find the duration between two dates. The duration to be measured can be specified: dhours dweeks ddays dminutes dyears To find out the number of days difference, the as.duration function calculates the duration in seconds so the duration must be divided by the desired duration (ddays) to convert to duration in days. road_accidents$date_diff &lt;- lubridate::as.duration(road_accidents$Date2 %--% road_accidents$Date1) / ddays(1) Table 5.4: Find difference between two dates acc_index Date1 Date2 date_diff 2017010001708 2017-08-05 2017-08-01 4 2017010009342 2017-01-01 2017-01-01 0 2017010009344 2017-01-01 2017-01-01 0 2017010009348 2017-01-01 2017-01-01 0 2017010009350 2017-01-01 2017-01-01 0 2017010009351 2017-01-01 2017-01-01 0 The %--% operator is used to define an interval. So, this code is calculating the duration of the interval between Date2 and Date1. The number after ddays indicates by how many units the duration is (i.e. one day). 5.1.8 Convert month (integer to character) {base} R has a useful function which takes the month numbers and converts them to the corresponding text. road_accidents$Month_lab &lt;- month.abb[road_accidents$Month] Table 5.5: Convert month to character acc_index Date Month Month_lab 2017010001708 2017-08-05 8 Aug 2017010009342 2017-01-01 1 Jan 2017010009344 2017-01-01 1 Jan 2017010009348 2017-01-01 1 Jan 2017010009350 2017-01-01 1 Jan 2017010009351 2017-01-01 1 Jan 5.1.9 Convert month (character to integer) {base} R has a useful function which takes the month text and converts them to the corresponding number. road_accidents$Month &lt;- match(road_accidents$Month_lab,month.abb) Table 5.6: Convert month character to integer acc_index Date Month Month_lab 2017010001708 2017-08-05 8 Aug 2017010009342 2017-01-01 1 Jan 2017010009344 2017-01-01 1 Jan 2017010009348 2017-01-01 1 Jan 2017010009350 2017-01-01 1 Jan 2017010009351 2017-01-01 1 Jan 5.1.10 Merge separate date information into a date The {lubridate} package can be used in conjunction with the paste function to combine columns separate date information (e.g. year, month, day) into one date variable. road_accidents$date &lt;- paste(road_accidents$Year, road_accidents$Month, road_accidents$Day, sep=&quot;-&quot;) %&gt;% ymd()%&gt;% as.Date() Table 5.7: Convert month to character acc_index Date Year Month Day date 2017010001708 2017-08-05 2017 8 5 2017-08-05 2017010009342 2017-01-01 2017 1 1 2017-01-01 2017010009344 2017-01-01 2017 1 1 2017-01-01 2017010009348 2017-01-01 2017 1 1 2017-01-01 2017010009350 2017-01-01 2017 1 1 2017-01-01 2017010009351 2017-01-01 2017 1 1 2017-01-01 5.2 Working with date-times A date-time stores date and time information. 5.2.1 Converting a character to a date-time This is similar to converting a character to a date as mentioned above. This can be done in the following way: Identify the order of the year, month, day, and time elements (hour, minute and second or just hour and minute) and use the appropriate function (ymd, mdy, dmy etc.) # convert date to date object # look at the date variable and see what order it is in (year-m-d, hms &quot;2017-11-28 14:00) # therefore use the ymd_hm road_accidents$Date_time1 &lt;- lubridate::ymd_hm(road_accidents$Date_time) 5.2.2 Extract date from date time variable Use the date function to extract the date from a date time variable. The year/month/day information can then be extracted from the date using the code examples above. road_accidents$Date2 &lt;- lubridate::date(road_accidents$Date_time) 5.2.3 Convert character to hms (time) variable Convert time as character into a hms variable so the variable can manipulated as a time object. This can be done using the {hms} package. road_accidents$Time &lt;- hms::as_hms(road_accidents$Time) 5.2.4 Extract hour from time Use the hour function from the {lubridate} package to extract hour information. road_accidents$hour &lt;- lubridate::hour(road_accidents$Time) See Table 5.8 for output 5.2.5 Extract minute from time Use the minute function from the {lubridate} package to extract minute information. road_accidents$minute &lt;- lubridate::minute(road_accidents$Time) See Table 5.8 for output 5.2.6 Extract second from time Use the second function from the {lubridate} package to extract second information. road_accidents$second &lt;- lubridate::second(road_accidents$Time) See Table 5.8 for output Table 5.8: Extract time information acc_index Time hour minute second 2017010001708 03:12:00 3 12 0 2017010009342 01:30:00 1 30 0 2017010009344 00:30:00 0 30 0 2017010009348 01:11:00 1 11 0 2017010009350 01:42:00 1 42 0 2017010009351 03:31:00 3 31 0 5.2.7 Merge separate time information into one variable Hour, minute and second variables can be merged to create a time variable, and then converted to hms. # merge seperate time information road_accidents$time2 &lt;- paste(road_accidents$hour,road_accidents$minute, road_accidents$second, sep=&quot;:&quot;) # convert to hms road_accidents$time3 &lt;- hms::as_hms(road_accidents$time2) #&gt; Warning: Lossy cast from &lt;character&gt; to &lt;hms&gt; at position(s) 31864, 34039, #&gt; 106469 Table 5.9: Merge time information acc_index hour minute second time3 2017010001708 3 12 0 03:12:00 2017010009342 1 30 0 01:30:00 2017010009344 0 30 0 00:30:00 2017010009348 1 11 0 01:11:00 2017010009350 1 42 0 01:42:00 2017010009351 3 31 0 03:31:00 5.2.8 find the difference between two times Use the {base} r difftime function to find the difference between two times. Note: this can also be used to find the difference in days or weeks. Also note: the object must be hms/date to be able to calculate the difference. time_first &lt;- hms::as.hms(&quot;11:00:00&quot;) #&gt; Warning: as.hms() is deprecated, please use as_hms(). #&gt; This warning is displayed once per session. time_second &lt;- hms::as.hms(&quot;11:05:00&quot;) difference &lt;- difftime(time_first, time_second, &quot;mins&quot; ) difference #&gt; Time difference of -5 mins Change the unit of measurement to get different time differences (for days and weeks you’ll need a date rather than a hms). Units: “secs”, “mins”, “hours”, “days”, “weeks” This special date is known as the Unix Epoch↩ "],
["factors.html", "Chapter 6 Working with factors 6.1 Common uses 6.2 Other things to know about factors 6.3 Helpful packages", " Chapter 6 Working with factors 6.1 Common uses Within the department there are three main ways you are likely to make use of factors: Tabulation of data (in particular when you want to illustrate zero occurences of a particular value) Ordering of data for output (e.g. bars in a graph) Statistical models (e.g. in conjunction with contrasts when encoding categorical data in formulae) 6.1.1 Tabulation of data # define a simple character vector vehicles_observed &lt;- c(&quot;car&quot;, &quot;car&quot;, &quot;bus&quot;, &quot;car&quot;) class(vehicles_observed) #&gt; [1] &quot;character&quot; table(vehicles_observed) #&gt; vehicles_observed #&gt; bus car #&gt; 1 3 # convert to factor with possible levels possible_vehicles &lt;- c(&quot;car&quot;, &quot;bus&quot;, &quot;motorbike&quot;, &quot;bicycle&quot;) vehicles_observed &lt;- factor(vehicles_observed, levels = possible_vehicles) class(vehicles_observed) #&gt; [1] &quot;factor&quot; table(vehicles_observed) #&gt; vehicles_observed #&gt; car bus motorbike bicycle #&gt; 3 1 0 0 6.1.2 Ordering of data for output # example 1 vehicles_observed &lt;- c(&quot;car&quot;, &quot;car&quot;, &quot;bus&quot;, &quot;car&quot;) possible_vehicles &lt;- c(&quot;car&quot;, &quot;bus&quot;, &quot;motorbike&quot;, &quot;bicycle&quot;) vehicles_observed &lt;- factor(vehicles_observed, levels = possible_vehicles) table(vehicles_observed) #&gt; vehicles_observed #&gt; car bus motorbike bicycle #&gt; 3 1 0 0 possible_vehicles &lt;- c(&quot;bicycle&quot;, &quot;bus&quot;, &quot;car&quot;, &quot;motorbike&quot;) vehicles_observed &lt;- factor(vehicles_observed, levels = possible_vehicles) table(vehicles_observed) #&gt; vehicles_observed #&gt; bicycle bus car motorbike #&gt; 0 1 3 0 # example 2 df &lt;- iris[sample(1:nrow(iris), 100), ] ggplot(df, aes(Species)) + geom_bar() df$Species &lt;- factor(df$Species, levels = c(&quot;versicolor&quot;, &quot;virginica&quot;, &quot;setosa&quot;)) ggplot(df, aes(Species)) + geom_bar() 6.1.3 Statistical models When building a regression model, R will automatically encode your independent character variables using contr.treatment contrasts. This means that each level of the vector is contrasted with a baseline level (by default the first level once the vector has been converted to a factor). If you want to change the baseline level or use a different encoding methodology then you need to work with factors. To illustrate this we use the Titanic dataset. # load data and convert to one observation per row data(&quot;Titanic&quot;) df &lt;- as.data.frame(Titanic) df &lt;- df[rep(1:nrow(df), df[ ,5]), -5] rownames(df) &lt;- NULL head(df) Class Sex Age Survived 3rd Male Child No 3rd Male Child No 3rd Male Child No 3rd Male Child No 3rd Male Child No 3rd Male Child No # For this example we convert all variables to characters df[] &lt;- lapply(df, as.character) # save to temporary folder filename &lt;- tempfile(fileext = &quot;.csv&quot;) write.csv(df, filename, row.names = FALSE) # reload data with stringsAsFactors = FALSE new_df &lt;- read.csv(filename, stringsAsFactors = FALSE) str(new_df) #&gt; &#39;data.frame&#39;: 2201 obs. of 4 variables: #&gt; $ Class : chr &quot;3rd&quot; &quot;3rd&quot; &quot;3rd&quot; &quot;3rd&quot; ... #&gt; $ Sex : chr &quot;Male&quot; &quot;Male&quot; &quot;Male&quot; &quot;Male&quot; ... #&gt; $ Age : chr &quot;Child&quot; &quot;Child&quot; &quot;Child&quot; &quot;Child&quot; ... #&gt; $ Survived: chr &quot;No&quot; &quot;No&quot; &quot;No&quot; &quot;No&quot; ... First lets see what happens if we try and build a logistic regression model for survivals but using our newly loaded dataframe model_1 &lt;- glm(Survived ~ ., family = binomial, data = new_df) #&gt; Error in eval(family$initialize): y values must be 0 &lt;= y &lt;= 1 This errors due to the Survived variable being a character vector. Let’s convert it to a factor. new_df$Survived &lt;- factor(new_df$Survived) model_2 &lt;- glm(Survived ~ ., family = binomial, data = new_df) summary(model_2) #&gt; #&gt; Call: #&gt; glm(formula = Survived ~ ., family = binomial, data = new_df) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.0812 -0.7149 -0.6656 0.6858 2.1278 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 2.0438 0.1679 12.171 &lt; 2e-16 *** #&gt; Class2nd -1.0181 0.1960 -5.194 2.05e-07 *** #&gt; Class3rd -1.7778 0.1716 -10.362 &lt; 2e-16 *** #&gt; ClassCrew -0.8577 0.1573 -5.451 5.00e-08 *** #&gt; SexMale -2.4201 0.1404 -17.236 &lt; 2e-16 *** #&gt; AgeChild 1.0615 0.2440 4.350 1.36e-05 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 2769.5 on 2200 degrees of freedom #&gt; Residual deviance: 2210.1 on 2195 degrees of freedom #&gt; AIC: 2222.1 #&gt; #&gt; Number of Fisher Scoring iterations: 4 This works, but the baseline case for Class is 1st. What if we wanted it to be 3rd. We would first need to convert the variable to a factor and choose the appropriate level as a baseline new_df$Class &lt;- factor(new_df$Class) levels(new_df$Class) #&gt; [1] &quot;1st&quot; &quot;2nd&quot; &quot;3rd&quot; &quot;Crew&quot; contrasts(new_df$Class) &lt;- contr.treatment(levels(new_df$Class), 3) model_3 &lt;- glm(Survived ~ ., family = binomial, data = new_df) summary(model_3) #&gt; #&gt; Call: #&gt; glm(formula = Survived ~ ., family = binomial, data = new_df) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.0812 -0.7149 -0.6656 0.6858 2.1278 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 0.2661 0.1293 2.058 0.0396 * #&gt; Class1st 1.7778 0.1716 10.362 &lt; 2e-16 *** #&gt; Class2nd 0.7597 0.1764 4.308 1.65e-05 *** #&gt; ClassCrew 0.9201 0.1486 6.192 5.93e-10 *** #&gt; SexMale -2.4201 0.1404 -17.236 &lt; 2e-16 *** #&gt; AgeChild 1.0615 0.2440 4.350 1.36e-05 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 2769.5 on 2200 degrees of freedom #&gt; Residual deviance: 2210.1 on 2195 degrees of freedom #&gt; AIC: 2222.1 #&gt; #&gt; Number of Fisher Scoring iterations: 4 6.2 Other things to know about factors Working with factors can be tricky to both the new, and the experienced R user. This is as their behaviour is not always intuitive. Below we illustrate three common areas of confusion 6.2.1 Renaming factor levels my_factor &lt;- factor(c(&quot;Dog&quot;, &quot;Cat&quot;, &quot;Hippo&quot;, &quot;Hippo&quot;, &quot;Monkey&quot;, &quot;Hippo&quot;)) my_factor #&gt; [1] Dog Cat Hippo Hippo Monkey Hippo #&gt; Levels: Cat Dog Hippo Monkey # change Hippo to Giraffe ## DO NOT DO THIS my_factor[my_factor == &quot;Hippo&quot;] &lt;- &quot;Giraffe&quot; #&gt; Warning in `[&lt;-.factor`(`*tmp*`, my_factor == &quot;Hippo&quot;, value = &quot;Giraffe&quot;): #&gt; invalid factor level, NA generated my_factor #&gt; [1] Dog Cat &lt;NA&gt; &lt;NA&gt; Monkey &lt;NA&gt; #&gt; Levels: Cat Dog Hippo Monkey ## reset factor my_factor &lt;- factor(c(&quot;Dog&quot;, &quot;Cat&quot;, &quot;Hippo&quot;, &quot;Hippo&quot;, &quot;Monkey&quot;, &quot;Hippo&quot;)) # change Hippo to Giraffe ## DO THIS levels(my_factor)[levels(my_factor) == &quot;Hippo&quot;] &lt;- &quot;Giraffe&quot; my_factor #&gt; [1] Dog Cat Giraffe Giraffe Monkey Giraffe #&gt; Levels: Cat Dog Giraffe Monkey 6.2.2 Combining factors does not result in a factor names_1 &lt;- factor(c(&quot;jon&quot;, &quot;george&quot;, &quot;bobby&quot;)) names_2 &lt;- factor(c(&quot;laura&quot;, &quot;claire&quot;, &quot;laura&quot;)) c(names_1, names_2) #&gt; [1] 3 2 1 2 1 2 # if you want concatenation of factors to give a factor than the help page for # c() suggest the following method is used: c.factor &lt;- function(..., recursive=TRUE) unlist(list(...), recursive=recursive) c(names_1, names_2) #&gt; [1] jon george bobby laura claire laura #&gt; Levels: bobby george jon claire laura # if you only wanted the result to be a character vector then you could also use c(as.character(names_1), as.character(names_2)) #&gt; [1] &quot;jon&quot; &quot;george&quot; &quot;bobby&quot; &quot;laura&quot; &quot;claire&quot; &quot;laura&quot; 6.2.3 Numeric vectors that have been read as factors Sometimes we find a numeric vector is being stored as a factor (a common occurence when reading a csv from Excel with #N/A values) # example data set pseudo_excel_csv &lt;- data.frame(names = c(&quot;jon&quot;, &quot;laura&quot;, &quot;ivy&quot;, &quot;george&quot;), ages = c(20, 22, &quot;#N/A&quot;, &quot;#N/A&quot;)) # save to temporary file filename &lt;- tempfile(fileext = &quot;.csv&quot;) write.csv(pseudo_excel_csv, filename, row.names = FALSE) # reload data df &lt;- read.csv(filename) str(df) #&gt; &#39;data.frame&#39;: 4 obs. of 2 variables: #&gt; $ names: Factor w/ 4 levels &quot;george&quot;,&quot;ivy&quot;,..: 3 4 2 1 #&gt; $ ages : Factor w/ 3 levels &quot;#N/A&quot;,&quot;20&quot;,&quot;22&quot;: 2 3 1 1 to transform this to a numeric variable we can proceed as follows df$ages &lt;- as.numeric(levels(df$ages)[df$ages]) #&gt; Warning: NAs introduced by coercion str(df) #&gt; &#39;data.frame&#39;: 4 obs. of 2 variables: #&gt; $ names: Factor w/ 4 levels &quot;george&quot;,&quot;ivy&quot;,..: 3 4 2 1 #&gt; $ ages : num 20 22 NA NA 6.3 Helpful packages If you find yourself having to manipulate factors often, then it may be worth spending some time with the tidyverse package forcats. This was designed to make working with factors simpler. There are many tutorials available online but a good place to start is the official vignette. "],
["plots.html", "Chapter 7 Plotting and Data Visualisations 7.1 Plotting in base R 7.2 Plotting withh {ggplot2} 7.3 DfT colours 7.4 Themes 7.5 Interactive charts with {plotly} 7.6 Mapping in R", " Chapter 7 Plotting and Data Visualisations This chapter provides some examples of how to visualise data in R. For charts, we’ll look at a few examples of how to create simple charts in base R but this chapter will focus mainly in using {ggplot2} to plot charts. For maps, we’ll look at how to produce static choropleth maps using {ggplot2} and how to produce interactive maps using {leaflet}. 7.1 Plotting in base R Before we look at using {ggplot2}, we’ll look at how to plot simple charts using functions in base R. We’ll use road accident data from 2005 to 2017 to demonstrate how to create line and bar charts. # read in road accident data road_acc &lt;- readr::read_csv( file = &quot;data/road_accidents_by_year_and_severity.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; accident_year = col_double(), #&gt; accident_severity_id = col_double(), #&gt; name = col_character(), #&gt; total = col_double() #&gt; ) head(road_acc) accident_year accident_severity_id name total 2005 1 Fatal 2913 2005 2 Serious 25029 2005 3 Slight 170793 2006 1 Fatal 2926 2006 2 Serious 24946 2006 3 Slight 161289 7.1.1 Line charts in base R We want to plot a line chart of total road accidents against year. First we need to group our data by accident year and summarise to get a total sum of accidents for each year: road_acc_total &lt;- road_acc %&gt;% dplyr::group_by(accident_year) %&gt;% dplyr::summarise(total = sum(total)) We’ll now use the base R function ‘plot’, specifying the x and y axis and well as the plot type ‘l’ for line charts: plot( x = road_acc_total$accident_year, y = road_acc_total$total, type = &quot;l&quot; ) We can make our plot look better by specifying a colour, labelling the axes and giving our plot a title: plot( x = road_acc_total$accident_year, y = road_acc_total$total, type = &quot;l&quot;, col = &quot;red&quot;, xlab = &quot;Year&quot;, ylab = &quot;Total&quot;, main = &quot;Total road accidents per year, 2005 - 2017&quot; ) We can also force our plot to start at 0: plot( x = road_acc_total$accident_year, y = road_acc_total$total, type = &quot;l&quot;, col = &quot;red&quot;, xlab = &quot;Year&quot;, ylab = &quot;Total&quot;, main = &quot;Total road accidents per year, 2005 - 2017&quot;, ylim=c(0, max(road_acc_total$total)) ) 7.1.2 Bar charts in base R We want to plot a bar chart showing the total number of accidents of each severity in 2017. First let’s filter the road accidents data for 2017: road_acc_2017 &lt;- road_acc %&gt;% dplyr::filter(accident_year == 2017) road_acc_2017 accident_year accident_severity_id name total 2017 1 Fatal 1676 2017 2 Serious 22534 2017 3 Slight 105772 To create a bar chart, we use the base R function ‘barplot’ and then specify the variable we want to plot as the height argument: barplot(height = road_acc_2017$total) This isn’t very useful as we can’t see what the different severity types are. So we can specify these in the names.arg argument, as well as add a few extra features to make the plot look better: barplot(height = road_acc_2017$total, names.arg = c(&quot;Fatal&quot;, &quot;Serious&quot;, &quot;Slight&quot;), width = 2, #width of the bars col = &quot;lightblue&quot;, xlab = &quot;Severity&quot;, ylab = &quot;Total accidents&quot;, main = &quot;Total accidents by severity, 2017&quot;) 7.2 Plotting withh {ggplot2} What is {ggplot2}? The ‘gg’ in {ggplot2} stands for ‘grammar of graphics’. This is a way of thinking about plotting as having grammar elements that can be applied in succession to create a plot. This is the idea that you can build every graph from the same few components: a dataset, geoms (marks representing data points), a co-ordinate system and some other things. The ggplot() function from the {ggplot2} package is how you create these plots. You build up the graphical elements using the + symbol. Think about it as placing down a canvas and then adding layers on top. Why should I use {ggplot2} instead of the plot functions in base R? As with most things in R, there are multiple ways to do the same thing. This applies to creating visualisations as well. As will be demonstrated below we can replicate the graphs we have created above using {ggplot2} instead, pretty well. One method is not necessarily better than the other, but at DfT we advocate using {ggplot2} when plotting charts. There is consistency in the way that {ggplot2} works which makes it easier to get to grips with for beginners. It is also part of the {tidyverse} which we have used earlier on in this cookbook so it shares the underlying design philosophy, grammar, and data structures. 7.2.1 Line charts with {ggplot2} When plotting with {ggplot2}, we start with the ggplot() function which creates a blank canvas, then the next layer we add is the plot type. For line charts, this would be ggplot() + geom_line(). Within these functions, we specify our data and our aesthetic mappings i.e. what variables to map to the x and y axes from the specified data. If we were create a simple line chart for total accidents against year, the code would read as follows: ggplot(data = road_acc_total) + geom_line(mapping = aes(x = accident_year, y = total)) So a reusuable template for making graphs would be as below, with the bracketed sections in the code replaced with a dataset, a geom function and a collection of mappings: ggplot(data = name_of_dataset) + geom_function(mapping = aes()) You can find a range of different plot types available in {ggplot2}, as well as tips on how to use them in the {ggplot2} cheatsheet (https://www.rstudio.com/wp-content/uploads/2016/11/ggplot2-cheatsheet-2.1.pdf). Let’s create the same the line chart we created with base R, showing total road accidents against year: ggplot(data = road_acc_total) + geom_line(aes(x = accident_year, y = total), col = &quot;red&quot;) + xlab(&quot;Year&quot;) + ylab(&quot;Total&quot;) + ggtitle(&quot;Total road accidents per year, 2005 - 2017&quot;) + scale_x_continuous(breaks = seq(2000, 2017, 2)) + expand_limits(y=0) + theme_classic() Here we have specified the colour of the line (notice this is outside of the aes() function). We have also labelled the x and y axes and given the plot a title. We have used scale_x_continuous() function to specify the intervals in the year variable and have used a theme to set the style of our plot (more on this later). 7.2.2 Aesthetic mappings To get more insight into our data, we can add a third variable to our plot by mapping it to an aesthetic. This is a visual property of the objects in our plot such as the size, the shape or the colour of our points. For example, if we want to see the total number of road accidents by severity type against year, we can map the ‘name’ variable to the colour aesthetic: ggplot(data = road_acc) + geom_line(mapping = aes(x = accident_year, y = total, colour = name)) + scale_x_continuous(breaks = seq(2000, 2017, 2)) So unlike before, we specify the colour within the aes() function, rather than outside of it. 7.2.3 Bar charts with {ggplot2} When creating bar charts with {ggplot2}, we can use geom_bar() or geom_col(). geom_bar() makes the height of the bar proportional to the number of cases in each group while geom_col() enables the heights of the bars to represent values in the data. So if your data is not already grouped you can use geom_bar() like so: messy_pokemon &lt;- readr::read_csv( file = &quot;data/messy_pokemon_data.csv&quot;) head(messy_pokemon) species combat_power hit_points weight_kg weight_bin height_m height_bin fast_attack charge_attack date_first_capture time_first_capture abra 101 20 17.18 normal 0.85 normal zen_headbutt shadow_ball 31 May 1977 20:59:33 abra 81 16 25.94 extra_large 1.00 normal zen_headbutt shadow_ball 24 February 1973 10:18:40 bellsprout 156 32 5.85 extra_large 0.80 normal acid sludge_bomb 21 June 1924 08:06:55 bellsprout 262 44 5.42 extra_large 0.82 normal acid sludge_bomb 01 August 1925 11:18:28 bellsprout 389 50 3.40 normal 0.66 normal vine_whip wrap 06 August 1952 21:11:42 bellsprout 433 59 6.67 extra_large 0.84 normal acid power_whip 17 January 1915 13:30:41 ggplot(data = messy_pokemon) + geom_bar(mapping = aes(x = weight_bin)) This has grouped our data by weight_bin with the height of the bars representing the number of pokemon in each weight bin. Let’s recreate the total accidents by severity chart, now using {ggplot2} instead: ggplot(data = road_acc_2017) + geom_col(mapping = aes(x = name, y = total), fill = &quot;lightblue&quot;, col = &quot;black&quot;)+ xlab(&quot;Severity&quot;) + ylab(&quot;Total accidents&quot;) + ggtitle(&quot;Total accidents by severity, 2017&quot;)+ theme_classic() Here we have used geom_col() instead but our data is already grouped so we simply want the height of the bars to represent the values in the data i.e. the number of accidents of each type of severity. You could also use geom_bar() in this situation but you would need to add an extra argument: stat = “identity”. ggplot(data = road_acc_2017) + geom_bar(mapping = aes(x = name, y = total), fill = &quot;lightblue&quot;, col = &quot;black&quot;, stat = &quot;identity&quot;)+ xlab(&quot;Severity&quot;) + ylab(&quot;Total accidents&quot;) + ggtitle(&quot;Total accidents by severity, 2017&quot;) + theme_classic() 7.3 DfT colours So far we’ve used colours built into R and referred to them by name e.g. red, lightlue etc. In order to make charts using DfT colours, we can specify what colours we want using hexcodes. For example, for the previous bar chart we can set the levels of severity to different DfT colours. ggplot(data = road_acc_2017) + geom_col(mapping = aes(x = name, y = total, fill = name), col = &quot;black&quot;)+ xlab(&quot;Severity&quot;) + ylab(&quot;Total accidents&quot;) + ggtitle(&quot;Total accidents by severity, 2017&quot;) + theme_classic() + scale_fill_manual(values = c(&quot;#C99212&quot;, &quot;#D25F15&quot;, &quot;#006853&quot;)) Here we map the name variable to the fill argument within the aesthetic. 7.4 Themes We mentioned themes earlier. Themes are used to set the style of your plot and can give your plots a consistent customized look. You can customise things such as titles, labels, fonts, background, gridlines, and legends. We have been using theme_classic() so far but {ggplot2} has a number of built-in themes that you can use for your plots available here: https://ggplot2.tidyverse.org/reference/ggtheme.html You can modify aspects of a theme using the theme() function. For example, for our previous accidents plot, we can remove the legend title and move the position of the plot title. ggplot(data = road_acc_2017) + geom_col(mapping = aes(x = name, y = total, fill = name), col = &quot;black&quot;)+ xlab(&quot;Severity&quot;) + ylab(&quot;Total accidents&quot;) + ggtitle(&quot;Total accidents by severity, 2017&quot;) + theme_classic() + scale_fill_manual(values = c(&quot;#C99212&quot;, &quot;#D25F15&quot;, &quot;#006853&quot;))+ theme(legend.title = element_blank(), plot.title = element_text(hjust = 0.5)) 7.4.1 Custom DfT Theme Instead of using the built-in themes, we can create our own theme to apply to our plots. Below I have created a ‘DfT theme’ for line charts which sets things such as the font types, sizes, axes lines and title positions to make the plot consistent with what we might put in a DfT publication. You can adjust and tweak this theme and the colours to create plots in the correct style for your own publications. # set DfT colours dft_colour &lt;- c(&quot;#006853&quot;, # dark green &quot;#66A498&quot;, # light green &quot;#D25F15&quot;, # orange &quot;#E49F73&quot;, # light orange &quot;#C99212&quot;, # yellow &quot;#E9D3A0&quot;, # pale yellow &quot;#0099A9&quot;, # blue &quot;#99D6DD&quot;) # light blue # create theme # note: &#39;sans&#39; in R refers to the font &#39;Arial&#39; in Windows theme_dft &lt;- ggplot2::theme(axis.text = element_text(family = &quot;sans&quot;, size = 10, colour = &quot;black&quot;), # axis text axis.title.x = element_text(family = &quot;sans&quot;, size = 13, colour = &quot;black&quot;, # x axis title margin = margin(t = 10)), axis.title.y = element_blank(), plot.title = element_text(size = 16, family = &quot;sans&quot;, hjust = 0.5), plot.subtitle = element_text(size = 13, colour = &quot;black&quot;, hjust = -0.05, margin = margin(t = 10)), legend.key = element_blank(), # make the legend background blank legend.position = &quot;bottom&quot;, # legend at the bottom legend.direction = &quot;horizontal&quot;, # legend horizontal legend.title = element_blank(), # remove legend title legend.text = element_text(size = 9, family = &quot;sans&quot;), axis.ticks = element_blank(), # remove tick marks panel.grid = element_blank(), # remove grid lines panel.background = element_blank(), # remove background axis.line.x = element_line(size = 0.5, colour = &quot;black&quot;)) # use the DfT colours and the DfT theme for the accidents by severity line chart ggplot(data = road_acc) + geom_line(mapping = aes(x = accident_year, y = total, colour = name), size = 1.5) + labs(title = &quot;Accidents by severity, 2005 to 2017&quot;, x = &quot;Accident Year&quot;, y = &quot;&quot;)+ scale_x_continuous(breaks = seq(2005, 2017, 2))+ scale_colour_manual(values = dft_colour) + #here is where you apply the dft colours theme_dft #here we specify our custom theme 7.5 Interactive charts with {plotly} {plotly} is a graphing library which makes interactive html graphs. It uses the open source JavaScript graphing library plotly.js. It is great for building dashboards or allowing the user to interact with the data themselves. {plotly} is not necessarily good for publications as the charts are html but can be useful for exploratory analysis or QA notes. It allows you to zoom into certain parts of the chart and toggle between different categories. It can be used in two ways - either with {ggplot2} (easier option) or using the plot_ly() wrapper directly which gives you more control. 7.5.1 {plotly} with {ggplot2} Taking our previous accidents by severity plot, we can simply assign this to an object and use the ggplotly() function to make it interactive. library(plotly) road_acc_chart &lt;- ggplot(data = road_acc) + geom_line(mapping = aes(x = accident_year, y = total, colour = name), size = 1.5) + labs(title = &quot;Accidents by severity, 2005 to 2017&quot;, x = &quot;Accident Year&quot;, y = &quot;&quot;)+ scale_x_continuous(breaks = seq(2005, 2017, 2))+ scale_colour_manual(values = dft_colour) + theme_dft plotly::ggplotly(road_acc_chart) #&gt; Warning: plotly.js does not (yet) support horizontal legend items #&gt; You can track progress here: #&gt; https://github.com/plotly/plotly.js/issues/53 Since we set our legend to be horizontal in our DfT theme, we get a warning message as plotly.js does not support horizontal legend items yet. 7.5.2 plot_ly() Using plot_ly() is similar to {ggplot2} in some ways as we build the plot in layers but we use the pipe operator rather than a plus sign, and the ~ sign before the variables in our data: plotly::plot_ly(road_acc, x = ~accident_year, y = ~total) %&gt;% # specify the data and x and y axes plotly::add_lines(color = ~name, colors = dft_colour[1:3]) %&gt;% # colour lines by severity plotly::layout(title = &quot;Accidents by severity, 2005 to 2017&quot;, xaxis = list(title = &quot;Accident Year&quot;), yaxis = list(title = &quot;&quot;)) You can find more information about using {plotly} in R from the following websites: Graphing library with example code: https://plot.ly/r/ Cheat sheet: https://images.plot.ly/plotly-documentation/images/r_cheat_sheet.pdf E-book: https://plotly-r.com/index.html 7.6 Mapping in R There are a wide range of packages you can use to produce maps in R. For static choropleth maps, we’re going to focus on using {ggplot2} which we are now familiar with. 7.6.1 Mapping with {ggplot2} To complete. 7.6.2 Mapping with {leaflet} The {leaflet} package can be used to create interactive maps in R. Similar to {ggplot2}, you start with a base map and then add layers (i.e. features). We’re going to map some search and rescue helicopter data, using the longitude and latitude. library(leaflet) sarh &lt;- readr::read_csv(file = &quot;data/SARH_spatial.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; Base = col_character(), #&gt; Unique_ID = col_character(), #&gt; Cat = col_character(), #&gt; latitude_new = col_double(), #&gt; longitude_new = col_double(), #&gt; Place = col_character(), #&gt; Domain = col_character() #&gt; ) head(sarh) Base Unique_ID Cat latitude_new longitude_new Place Domain Sumburgh Sumb6559171 Rescue/Recovery 61.10333 1.073333 Cormorant Alpha Maritime Caernarfon Caer6580171 Support 51.88602 -5.307241 Whitesands Bay Coastal Humberside Humb6587171 Rescue/Recovery 53.39779 -1.903712 Kinder Scout Land Prestwick Pres6613171 Rescue/Recovery 56.33115 -4.618574 Beinn A Chroin Land Inverness Inve6614171 Rescue/Recovery 56.80076 -5.034575 Ben Nevis Land Newquay Newq6617171 Search only 50.04000 -5.636667 Porthcurno Maritime #plot the interactive map using leaflet leaflet::leaflet(data = sarh) %&gt;% leaflet::addProviderTiles(provider = providers$Esri.NatGeoWorldMap) %&gt;% #select the type of map you want to plot leaflet::addMarkers(lng = ~longitude_new, lat = ~ latitude_new, popup = ~ htmltools::htmlEscape(Base), # what appears when you click on a data point label = ~ htmltools::htmlEscape(Domain) # what appears when you hover over a data point ) If you want to save this as a static map, you could simply export is an image. More information on using {leaflet} in R can be found here: https://rstudio.github.io/leaflet/ "]
]
